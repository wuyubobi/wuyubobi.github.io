---
layout:     post
title:      “Python爬虫学习-第一个爬虫”
subtitle:   “Python 学习历程”
date:       2017-10-17
author:     "ZhangBo"
header-img: "img/post-bg-unix-linux.jpg"
catalog: true
tags:
- 爬虫
- Python
---
### Python爬虫学习

##### 第一个爬虫 百度贴吧爬虫

基于 python2.7版本

1. 网络库使用 urllib2
2. 解析库使用 lxml Xpath 方式解析
3. 字符串编码 urllib

主要步骤:

1. 通过实际访问页面获取百度贴吧页面访问规律
	- 不变的 url部分 https://tieba.baidu.com/f?
	- ?后面拼接贴吧关键字的HTML 编码 rullib.urlencode({"kw":"关键字"})
	- 关键字后面拼接页码 形式为: &数\*50
2. 通过 urllib2对拼接后的网页进行请求
	- 首先用一个正常浏览器的请求头代替 python 的请求头  防止被封 request = urllib2.Request(url, headers="定义的请求头")
	- 通过 response = urllib2.urlopen("上一步封装的请求(request)")访问目标页面
	- 通过 response.read() 得到目标页面的源码
3. 使用 lxml 中的 etree 方法对得到的页面源码进行解析
	- 通过 etree.HTML("页面源码")得到解析对象content
	- 通过 content.xpath('匹配规则') 得到想要的数据的集合
	- 当然这里可以通过解析出来的图片地址再次封装请求将贴吧图片进行下载

##### 这个过程中遇到的坑

1. 匹配规则写的没有任何问题, 但是爬虫就是无法匹配出任何数据
	-  [x] 通过断点调试, 看是否真正的拿到了网页源码
	-  [x] 正确拿到源码, 仍无法匹配, 可能是请求头出了问题, 不同的请求头访问服务器, 服务器可能会针对相应的浏览器做出优化
2. 匹配的内容与预期不符, 多了或者是少了
	- [x] 多了可能是匹配的规则太宽泛, 应再向下一个节点 或者是多加一个规则判断
	- [x] 少了可能是规则只适应了部分界面的数据 假如网站会员的数据和普通用户数据结构不一致 就有可能出现漏爬的现象 一般可以向上一个节点找到二者相同的节点进行匹配处理    
